{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "models_to_analyze = {\n",
    "    'alexnet': {'input_size': 227, 'model_loader': models.alexnet},\n",
    "    'resnet50': {'input_size': 224, 'model_loader': models.resnet50},\n",
    "    'mobilenet_v2': {'input_size': 224, 'model_loader': models.mobilenet_v2},\n",
    "}\n",
    "\n",
    "N = 4 # Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_density(tensor):\n",
    "    if tensor.numel() == 0:\n",
    "        return 0.0\n",
    "    non_zeros = torch.count_nonzero(tensor)\n",
    "    density = non_zeros.float() / tensor.numel()\n",
    "    return density.item()\n",
    "\n",
    "def calculate_output_dim(input_dim, kernel_size, stride, padding, dilation):\n",
    "    if isinstance(kernel_size, int): kernel_size = (kernel_size, kernel_size)\n",
    "    if isinstance(stride, int): stride = (stride, stride)\n",
    "    if isinstance(padding, int): padding = (padding, padding)\n",
    "    if isinstance(dilation, int): dilation = (dilation, dilation)\n",
    "\n",
    "    output_h = math.floor(((input_dim[0] + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) / stride[0]) + 1)\n",
    "    output_w = math.floor(((input_dim[1] + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) / stride[1]) + 1)\n",
    "    return output_h, output_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing alexnet ---\n",
      "  Layer: Conv2d, Activation: ReLU\n",
      "  Parameters:\n",
      "    C: 3, M: 64, R: 11, S: 11\n",
      "    N: 4, P (expected): 56, Q (expected): 56\n",
      "    Hstride: 4, Wstride: 4\n",
      "    Padding: (2, 2)\n",
      "    Dilation: (1, 1)\n",
      "  Tensor Shapes:\n",
      "    Input: (4, 3, 227, 227)\n",
      "    Weights: (64, 3, 11, 11)\n",
      "    Output (Post-Activation): (4, 64, 56, 56)\n",
      "  Densities:\n",
      "    Input:   1.000000\n",
      "    Weights: 1.000000\n",
      "    Output (Post-Activation):  0.418981\n",
      "------------------------------\n",
      "--- Analyzing resnet50 ---\n",
      "  Layer: Conv2d, Activation: ReLU\n",
      "  Parameters:\n",
      "    C: 3, M: 64, R: 7, S: 7\n",
      "    N: 4, P (expected): 112, Q (expected): 112\n",
      "    Hstride: 2, Wstride: 2\n",
      "    Padding: (3, 3)\n",
      "    Dilation: (1, 1)\n",
      "  Tensor Shapes:\n",
      "    Input: (4, 3, 224, 224)\n",
      "    Weights: (64, 3, 7, 7)\n",
      "    Output (Post-Activation): (4, 64, 112, 112)\n",
      "  Densities:\n",
      "    Input:   1.000000\n",
      "    Weights: 1.000000\n",
      "    Output (Post-Activation):  0.657259\n",
      "------------------------------\n",
      "--- Analyzing mobilenet_v2 ---\n",
      "  Layer: Conv2d, Activation: ReLU6\n",
      "  Parameters:\n",
      "    C: 3, M: 32, R: 3, S: 3\n",
      "    N: 4, P (expected): 112, Q (expected): 112\n",
      "    Hstride: 2, Wstride: 2\n",
      "    Padding: (1, 1)\n",
      "    Dilation: (1, 1)\n",
      "  Tensor Shapes:\n",
      "    Input: (4, 3, 224, 224)\n",
      "    Weights: (32, 3, 3, 3)\n",
      "    Output (Post-Activation): (4, 32, 112, 112)\n",
      "  Densities:\n",
      "    Input:   1.000000\n",
      "    Weights: 1.000000\n",
      "    Output (Post-Activation):  0.595683\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, config in models_to_analyze.items():\n",
    "    print(f\"--- Analyzing {model_name} ---\")\n",
    "\n",
    "    model = config['model_loader'](pretrained=True).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    first_conv_layer = None\n",
    "    activation_layer = None\n",
    "    batch_norm_layer = None\n",
    "\n",
    "    if model_name == 'alexnet':\n",
    "        first_conv_layer = model.features[0]\n",
    "        activation_layer = model.features[1]\n",
    "        C = 3\n",
    "    elif model_name == 'resnet50':\n",
    "        first_conv_layer = model.conv1\n",
    "        batch_norm_layer = model.bn1\n",
    "        activation_layer = model.relu\n",
    "        C = first_conv_layer.in_channels\n",
    "    elif model_name == 'mobilenet_v2':\n",
    "        first_conv_layer = model.features[0][0]\n",
    "        batch_norm_layer = model.features[0][1]\n",
    "        activation_layer = model.features[0][2]\n",
    "        C = first_conv_layer.in_channels\n",
    "    else:\n",
    "        print(f\"Don't know how to find the layers for {model_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    if not isinstance(first_conv_layer, nn.Conv2d):\n",
    "         print(f\"Identified first layer for {model_name} is not nn.Conv2d. Skipping.\")\n",
    "         continue\n",
    "    if activation_layer is None:\n",
    "         print(f\"Could not find activation layer for {model_name}. Skipping.\")\n",
    "         continue\n",
    "\n",
    "\n",
    "    M = first_conv_layer.out_channels\n",
    "    kernel_size = first_conv_layer.kernel_size\n",
    "    R, S = kernel_size\n",
    "    stride = first_conv_layer.stride\n",
    "    Hstride, Wstride = stride\n",
    "    padding = first_conv_layer.padding\n",
    "    dilation = first_conv_layer.dilation\n",
    "    Hdilation, Wdilation = dilation\n",
    "    weights = first_conv_layer.weight.data\n",
    "\n",
    "    input_height = config['input_size']\n",
    "    input_width = config['input_size']\n",
    "    dummy_input = torch.randn(N, C, input_height, input_width).to(device)\n",
    "\n",
    "    output_activations = None\n",
    "    with torch.no_grad():\n",
    "        x = first_conv_layer(dummy_input)\n",
    "        if batch_norm_layer:\n",
    "             x = batch_norm_layer(x)\n",
    "        output_activations = activation_layer(x)\n",
    "\n",
    "    input_density = calculate_density(dummy_input)\n",
    "    weight_density = calculate_density(weights)\n",
    "    output_density = calculate_density(output_activations)\n",
    "\n",
    "    Q, P = calculate_output_dim((input_height, input_width), kernel_size, stride, padding, dilation)\n",
    "\n",
    "    layer_info = {\n",
    "        'Layer Type': type(first_conv_layer).__name__,\n",
    "        'Activation Type': type(activation_layer).__name__,\n",
    "        'Input Channels (C)': C,\n",
    "        'Output Channels (M)': M,\n",
    "        'Kernel Size (R, S)': kernel_size,\n",
    "        'Stride (Hstride, Wstride)': stride,\n",
    "        'Padding': padding,\n",
    "        'Dilation (Hdilation, Wdilation)': dilation,\n",
    "        'Input Tensor Shape': tuple(dummy_input.shape),\n",
    "        'Weight Tensor Shape': tuple(weights.shape),\n",
    "        'Output Tensor Shape (Post-Activation)': tuple(output_activations.shape),\n",
    "        'Calculated Output Dim (Q, P)': (Q, P),\n",
    "        'Input Density': f\"{input_density:.6f}\",\n",
    "        'Weight Density': f\"{weight_density:.6f}\",\n",
    "        'Output Activation Density (Post-Activation)': f\"{output_density:.6f}\",\n",
    "    }\n",
    "    results[model_name] = layer_info\n",
    "\n",
    "    print(f\"  Layer: {layer_info['Layer Type']}, Activation: {layer_info['Activation Type']}\")\n",
    "    print(f\"  Parameters:\")\n",
    "    print(f\"    C: {C}, M: {M}, R: {R}, S: {S}\")\n",
    "    print(f\"    N: {N}, P (expected): {P}, Q (expected): {Q}\")\n",
    "    print(f\"    Hstride: {Hstride}, Wstride: {Wstride}\")\n",
    "    print(f\"    Padding: {padding}\")\n",
    "    print(f\"    Dilation: {dilation}\")\n",
    "    print(f\"  Tensor Shapes:\")\n",
    "    print(f\"    Input: {layer_info['Input Tensor Shape']}\")\n",
    "    print(f\"    Weights: {layer_info['Weight Tensor Shape']}\")\n",
    "    print(f\"    Output (Post-Activation): {layer_info['Output Tensor Shape (Post-Activation)']}\")\n",
    "    print(f\"  Densities:\")\n",
    "    print(f\"    Input:   {layer_info['Input Density']}\")\n",
    "    print(f\"    Weights: {layer_info['Weight Density']}\")\n",
    "    print(f\"    Output (Post-Activation):  {layer_info['Output Activation Density (Post-Activation)']}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
